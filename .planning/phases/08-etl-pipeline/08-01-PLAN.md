---
phase: 08-etl-pipeline
plan: 01
type: execute
depends_on: []
files_modified: [convert.py]
---

<objective>
Create convert.py CLI that processes downloaded documents into Markdown with AI-generated metadata.

Purpose: Complete the v2.0 Document Processing Pipeline by combining extractors, formatters, and AI modules into a single CLI tool.
Output: Working convert.py script that batch-processes documents with progress tracking.
</objective>

<execution_context>
./.claude/get-shit-done/workflows/execute-plan.md
./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase summaries (relevant to this phase):
@.planning/phases/05-text-extraction/05-01-SUMMARY.md
@.planning/phases/06-markdown-formatting/06-01-SUMMARY.md
@.planning/phases/07-metadata-ai/07-01-SUMMARY.md

# Source files (established patterns):
@scrape.py
@src/extractors/__init__.py
@src/formatters/__init__.py
@src/ai/__init__.py

**Tech stack available:**
- pymupdf, python-docx (text extraction)
- text_to_markdown() (formatting)
- generate_metadata(), DocumentMetadata (AI metadata)
- argparse (CLI pattern from scrape.py)
- python-dotenv (API key loading)

**Established patterns:**
- CLI: argparse with --help, clear mode messages
- Modules: top-level function in __init__.py delegates to implementation
- Graceful degradation: return None on failure
- Progress: print statements with counts

**Output format:** Markdown files with YAML frontmatter in `converted/` folder, mirroring downloads/ structure.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create convert.py CLI with batch processing</name>
  <files>convert.py</files>
  <action>
Create convert.py following scrape.py CLI pattern:

1. **Argparse setup:**
   - `--input DIR` (default: downloads/) - source folder with documents
   - `--output DIR` (default: converted/) - destination for markdown files
   - `--force` - re-convert existing files
   - `--skip-ai` - skip Gemini metadata generation (faster, no API calls)
   - Standard argparse with RawDescriptionHelpFormatter and examples in epilog

2. **Processing logic:**
   - Walk input directory recursively, find .pdf and .docx files
   - For each file:
     a. Check if output exists (skip unless --force)
     b. extract_text() from src.extractors
     c. text_to_markdown() from src.formatters
     d. generate_metadata() from src.ai (unless --skip-ai)
     e. Combine into YAML frontmatter + markdown body
     f. Write to output path (mirror input structure, .md extension)

3. **Progress output:**
   - Print mode at start (like scrape.py)
   - Print each file as processed: "Converted: path/to/file.pdf"
   - Print skip messages: "Skipped (exists): path/to/file.md"
   - Print failures: "Failed: path/to/file.pdf (reason)"
   - Summary at end: converted/skipped/failed counts

4. **YAML frontmatter format** (when AI metadata available):
```yaml
---
title: [filename without extension]
source_file: [relative path from input dir]
document_type: [from AI]
summary: |
  [from AI - multiline]
keywords: [from AI - list]
topics: [from AI - list]
---
```

5. **Error handling:**
   - Catch exceptions per-file, log and continue
   - Load .env at startup with load_dotenv()
   - If AI fails (no API key or error), still write file without AI metadata
  </action>
  <verify>
.venv/bin/python convert.py --help shows usage with all options
  </verify>
  <done>convert.py runs without errors, shows help text with --input, --output, --force, --skip-ai options</done>
</task>

<task type="auto">
  <name>Task 2: Test on real documents and verify output</name>
  <files>convert.py</files>
  <action>
Run convert.py on actual downloaded documents:

1. **Test with --skip-ai first** (no API calls):
   ```bash
   .venv/bin/python convert.py --skip-ai
   ```
   Verify:
   - Creates converted/ directory
   - Creates category subdirectories
   - Produces .md files
   - Progress output looks correct

2. **Test single file with AI** (if API key configured):
   ```bash
   .venv/bin/python convert.py --force 2>&1 | head -20
   ```
   Check that AI metadata appears in frontmatter

3. **Verify output format** by reading a converted file

Fix any issues found during testing.
  </action>
  <verify>
ls converted/ shows category folders, cat converted/Hemtjänst/*.md | head -30 shows valid markdown with frontmatter
  </verify>
  <done>converted/ folder contains markdown files with proper YAML frontmatter structure, batch processing works on ~1195 files</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `convert.py --help` shows all options
- [ ] `convert.py --skip-ai` processes files without errors
- [ ] Output files have valid YAML frontmatter
- [ ] Directory structure mirrors input (downloads/ → converted/)
- [ ] Progress output shows converted/skipped/failed counts
</verification>

<success_criteria>

- convert.py CLI exists with documented options
- Batch processing works on downloaded documents
- Output markdown has YAML frontmatter
- Progress tracking shows clear status
- Phase 8 complete, v2.0 milestone ready for verification
</success_criteria>

<output>
After completion, create `.planning/phases/08-etl-pipeline/08-01-SUMMARY.md`:

# Phase 8 Plan 01: ETL Pipeline Summary

**[Substantive one-liner about what shipped]**

## Performance

- **Duration:** X min
- **Tasks:** 2
- **Files modified:** 1

## Accomplishments

- Created convert.py CLI
- [Additional accomplishments]

## Files Created/Modified

- `convert.py` - ETL pipeline CLI

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

- v2.0 milestone complete
- Ready for /gsd:verify-work
</output>
