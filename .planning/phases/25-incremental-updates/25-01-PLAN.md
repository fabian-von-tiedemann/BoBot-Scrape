---
phase: 25-incremental-updates
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [pipeline.py, scrape.py]
autonomous: true
---

<objective>
Implement incremental update detection to process only new or changed documents.

Purpose: Avoid re-processing unchanged documents across pipeline runs. The existing skip-existing logic only checks if output files exist, not if source documents have changed.
Output: Updated pipeline that compares current scan against previous run and processes only changed documents.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/24-pipeline-runner/24-01-SUMMARY.md

# Source files:
@pipeline.py
@scrape.py
@convert.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add manifest file for tracking document state</name>
  <files>pipeline.py</files>
  <action>
Implement a manifest system to track document state between runs:

1. **Manifest file format (manifest.json in run directory):**
   ```json
   {
     "run_id": "2026-01-16-1430",
     "created": "2026-01-16T14:30:00Z",
     "document_count": 1149,
     "documents": {
       "Bemanningsenheten/Bemanningspolicy.pdf": {
         "url": "https://...",
         "url_hash": "abc123",  // MD5 hash of URL for quick comparison
         "category": "Bemanningsenheten",
         "subcategory": "Bemanna med timvikarier"
       }
     }
   }
   ```

2. **Add to pipeline.py:**
   - Function `create_manifest(csv_path: Path) -> dict` that reads documents.csv and creates manifest structure
   - Function `save_manifest(manifest: dict, run_dir: Path)` that writes manifest.json
   - Function `load_manifest(run_dir: Path) -> dict | None` that reads existing manifest
   - After scrape stage completes, create and save manifest from documents.csv

3. **Implementation notes:**
   - Use hashlib.md5 for URL hashing (fast, no security concerns)
   - Store manifest.json in run directory alongside converted/, indexes/, etc.
   - Use ISO 8601 format for timestamps

Pattern: Follow existing JSON handling patterns in codebase.
  </action>
  <verify>python pipeline.py --skip-scrape --skip-ai creates manifest.json in run directory</verify>
  <done>manifest.json created with document URLs and hashes</done>
</task>

<task type="auto">
  <name>Task 2: Implement diff detection between runs</name>
  <files>pipeline.py</files>
  <action>
Add diff detection to compare current documents against previous run:

1. **Add CLI argument:**
   - `--prev-run DIR` optional previous run directory to compare against
   - When provided, load manifest from previous run

2. **Add function `compute_diff(current: dict, previous: dict) -> dict`:**
   Returns dict with:
   ```python
   {
     "new": ["path/to/new1.pdf", ...],      # In current but not previous
     "changed": ["path/to/changed.pdf", ...], # URL hash differs
     "removed": ["path/to/old.pdf", ...],   # In previous but not current
     "unchanged": ["path/to/same.pdf", ...]  # URL hash matches
   }
   ```

3. **Print diff summary after scrape stage:**
   ```
   Document changes detected:
     New: 5 documents
     Changed: 3 documents
     Removed: 2 documents
     Unchanged: 1139 documents
   ```

4. **Store diff in manifest:**
   Add `"diff"` key to manifest when --prev-run is used, containing the diff results.

Pattern: Simple dict comparison, no complex algorithms needed.
  </action>
  <verify>python pipeline.py --skip-scrape --skip-ai --prev-run runs/test-run shows diff summary</verify>
  <done>Diff detection works, showing new/changed/removed/unchanged counts</done>
</task>

<task type="auto">
  <name>Task 3: Add incremental convert mode</name>
  <files>pipeline.py, convert.py</files>
  <action>
Modify convert stage to process only changed documents when diff is available:

1. **Add to convert.py:**
   - `--include-files FILE` argument that accepts a text file with list of relative paths (one per line) to process
   - When provided, only process documents in this list (skip others entirely, not just if output exists)

2. **Add to pipeline.py:**
   - When diff is computed and has new/changed documents, write them to a temp file
   - Pass `--include-files {temp_file}` to convert.py
   - Report: "Converting 8 changed documents (skipping 1141 unchanged)"

3. **Behavior:**
   - Without --prev-run: convert.py behaves as before (skip existing by default, --force to reconvert)
   - With --prev-run: only new+changed documents are converted, others are skipped entirely

4. **Edge case:**
   - If --prev-run is provided but no documents changed: print "No changes detected, skipping convert stage" and continue to index/prompts

Pattern: Use tempfile.NamedTemporaryFile for the include list.
  </action>
  <verify>
Create a test by running:
1. python pipeline.py --skip-scrape --skip-ai (creates run with manifest)
2. python pipeline.py --skip-scrape --skip-ai --prev-run runs/{first-run}
Second run should show "No changes detected" and skip convert stage.
  </verify>
  <done>Convert stage respects diff and only processes changed documents</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python pipeline.py --help` shows --prev-run option
- [ ] First run creates manifest.json in run directory
- [ ] Second run with --prev-run shows diff summary
- [ ] Convert stage skips unchanged documents when --prev-run is used
- [ ] All stages complete successfully
</verification>

<success_criteria>
- Manifest file tracks document URLs and hashes per run
- Diff detection identifies new, changed, removed, unchanged documents
- Convert stage processes only changed documents when --prev-run provided
- Pipeline completes successfully with incremental mode
</success_criteria>

<output>
After completion, create `.planning/phases/25-incremental-updates/25-01-SUMMARY.md`
</output>
