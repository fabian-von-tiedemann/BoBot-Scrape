---
phase: 07-metadata-ai
plan: 01
type: execute
depends_on: []
files_modified: [requirements.txt, src/ai/__init__.py, src/ai/gemini.py]
---

<objective>
Integrate Gemini 3 Flash Preview for AI-powered metadata generation: summaries, keywords, and topics.

Purpose: Transform raw document text into enriched content with AI-generated metadata for RAG/GraphRAG integration.
Output: src/ai module with generate_metadata() function using google-genai SDK.
</objective>

<execution_context>
./.claude/get-shit-done/workflows/execute-plan.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-markdown-formatting/06-01-SUMMARY.md
@src/extractors/__init__.py
@src/formatters/markdown.py

**Tech stack available:**
- pymupdf, python-docx (from Phase 5)
- Regex-based formatters (from Phase 6)

**Established patterns:**
- Module pattern: top-level function in __init__.py delegates to internal implementation
- Graceful degradation: return None for failures instead of exceptions
- File type dispatch pattern from extractors

**API Discovery (Level 2):**
Using google-genai SDK (unified SDK, replaces deprecated google-generativeai).
Model ID: `gemini-3-flash-preview`
Client initialization: `client = genai.Client()` (reads GEMINI_API_KEY from env)
Structured output: Use Pydantic models with response_schema parameter.

**Prior decisions:**
- Phase 5: pymupdf over pdfplumber for speed
- Phase 6: Regex-based header detection for Swedish documents
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add google-genai dependency and create ai module</name>
  <files>requirements.txt, src/ai/__init__.py</files>
  <action>
1. Add `google-genai>=1.0.0` to requirements.txt
2. Create src/ai/ directory with __init__.py
3. In __init__.py: export generate_metadata function (import from .gemini)
4. Follow established module pattern from extractors/formatters

Do NOT use the deprecated google-generativeai package.
  </action>
  <verify>python -c "from src.ai import generate_metadata" succeeds</verify>
  <done>google-genai in requirements.txt, src/ai module importable</done>
</task>

<task type="auto">
  <name>Task 2: Implement Gemini metadata generator with structured output</name>
  <files>src/ai/gemini.py</files>
  <action>
Create generate_metadata() function:

1. Define Pydantic model for structured response:
   ```python
   class DocumentMetadata(BaseModel):
       summary: str          # 2-3 sentence summary
       keywords: list[str]   # 5-10 relevant keywords
       topics: list[str]     # 2-4 topic categories
       document_type: str    # rutin, policy, instruktion, etc.
   ```

2. Initialize Gemini client:
   ```python
   from google import genai
   from google.genai import types

   client = genai.Client()  # Reads GEMINI_API_KEY from env
   ```

3. Call gemini-3-flash-preview with structured output:
   ```python
   response = client.models.generate_content(
       model="gemini-3-flash-preview",
       contents=f"Analyze this Swedish municipal document and extract metadata:\n\n{text}",
       config=types.GenerateContentConfig(
           response_mime_type="application/json",
           response_schema=DocumentMetadata,
           thinking_config=types.ThinkingConfig(thinking_level="low")  # Fast, cheap
       )
   )
   return response.parsed
   ```

4. Add graceful error handling:
   - Return None if API fails
   - Log warning with error details
   - Handle missing API key gracefully

5. Add rate limit awareness:
   - Include optional delay parameter (default 0.1s between calls)
   - Log token usage if available in response
  </action>
  <verify>
Test with real document:
```python
from src.extractors import extract_text
from src.ai import generate_metadata
text = extract_text("downloads/Rutiner - Arbetsmiljö/RUTIN Arbetsmiljö-och-rehabilitering.pdf")
metadata = generate_metadata(text[:2000])  # First 2000 chars for test
print(metadata)
```
  </verify>
  <done>generate_metadata() returns DocumentMetadata with summary, keywords, topics, document_type OR None on error</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Gemini 3 Flash Preview integration with structured metadata output</what-built>
  <how-to-verify>
    1. Ensure GEMINI_API_KEY is set: `echo $GEMINI_API_KEY`
    2. If not set, get key from https://aistudio.google.com/apikey
    3. Export: `export GEMINI_API_KEY=your_key_here`
    4. Run test:
       ```bash
       cd /Users/fabianvontiedemann/kod/BoBot-Scrape
       .venv/bin/python -c "
       from src.extractors import extract_text
       from src.ai import generate_metadata
       text = extract_text('downloads/Rutiner - Arbetsmiljö/RUTIN Arbetsmiljö-och-rehabilitering.pdf')
       metadata = generate_metadata(text[:2000])
       print('Summary:', metadata.summary[:100] if metadata else 'FAILED')
       print('Keywords:', metadata.keywords if metadata else 'FAILED')
       print('Topics:', metadata.topics if metadata else 'FAILED')
       print('Type:', metadata.document_type if metadata else 'FAILED')
       "
       ```
    5. Verify response contains Swedish text and reasonable metadata
  </how-to-verify>
  <resume-signal>Type "approved" if metadata looks reasonable, or describe issues</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] google-genai in requirements.txt
- [ ] src/ai module exists with generate_metadata() export
- [ ] Uses gemini-3-flash-preview model (NOT deprecated gemini-flash-2 or google-generativeai)
- [ ] Structured output with Pydantic model
- [ ] Graceful error handling (returns None on failure)
- [ ] Test with real Swedish document succeeds
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- generate_metadata() returns structured DocumentMetadata
- Works with Swedish rutindokument content
- No hardcoded API keys (uses GEMINI_API_KEY env var)
</success_criteria>

<output>
After completion, create `.planning/phases/07-metadata-ai/07-01-SUMMARY.md`:

# Phase 7 Plan 01: Gemini Metadata Generator Summary

**[Substantive one-liner]**

## Performance

- **Duration:** X min
- **Started:** timestamp
- **Completed:** timestamp
- **Tasks:** 3
- **Files modified:** 3

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Task Commits

1. **Task 1: ...** - `hash` (type)
2. **Task 2: ...** - `hash` (type)

## Files Created/Modified

- `path` - Description

## Decisions Made

[Key decisions and rationale, or "None"]

## Deviations from Plan

[Changes from plan, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

- AI metadata generation ready for ETL pipeline integration
- Phase 8 can use generate_metadata() in batch processing
</output>
