---
phase: 28-question-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/qa/__init__.py
  - src/qa/question.py
  - generate_qa.py
  - qa/questions.yaml
autonomous: true

must_haves:
  truths:
    - "Running generate_qa.py on a document produces 3-5 questions in Swedish"
    - "Each question is formulated from a specific persona's perspective"
    - "Each question includes source document and section reference"
    - "Batch mode processes documents with Rich progress bar"
    - "Questions saved to qa/questions.yaml grouped by category"
  artifacts:
    - path: "src/qa/question.py"
      provides: "Question generation model and logic"
      exports: ["GeneratedQuestion", "QuestionBatch", "QuestionEntry", "generate_questions_for_document", "process_documents_batch", "deduplicate_questions", "write_questions_yaml"]
    - path: "qa/questions.yaml"
      provides: "Generated questions output file"
      contains: "categories:"
  key_links:
    - from: "generate_qa.py"
      to: "src/qa/question.py"
      via: "import generate functions"
      pattern: "from src.qa import.*generate"
    - from: "src/qa/question.py"
      to: "src/ai/gemini.py"
      via: "follows Gemini structured output pattern"
      pattern: "response_schema=QuestionBatch"
    - from: "src/qa/question.py"
      to: "src/qa/persona.py"
      via: "uses Persona model"
      pattern: "from .persona import Persona"
---

<objective>
Implement question generation that produces 3-5 persona-driven questions per document using Gemini structured outputs.

Purpose: Enable generation of training data for AI assistant - questions that sound like real care workers would ask.
Output: Working CLI that generates questions and saves to qa/questions.yaml with full metadata.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-question-generation/28-CONTEXT.md
@.planning/phases/28-question-generation/28-RESEARCH.md
@.planning/phases/27-core-infrastructure/27-01-SUMMARY.md

# Existing code to extend
@src/qa/persona.py
@src/qa/__init__.py
@src/ai/gemini.py
@generate_qa.py
@config/personas.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create question.py with Pydantic models and generation prompt</name>
  <files>src/qa/question.py, src/qa/__init__.py</files>
  <action>
Create src/qa/question.py with:

1. GeneratedQuestion Pydantic model for Gemini structured output:
   - question: str (fragan pa svenska)
   - question_type: Literal["factual", "procedural", "situational", "clarification"]
   - section_reference: str (dokumentsektion)
   - confidence: float (0.0-1.0)

2. QuestionBatch Pydantic model:
   - questions: list[GeneratedQuestion] (min_length=3, max_length=5)

3. QuestionEntry Pydantic model for YAML output:
   - question: str
   - source_document: str (relative path like "Hemtjanst/rutin.md")
   - section: str
   - question_type: str
   - persona: dict (full persona details: roll, erfarenhet, situation, sprakbakgrund)
   - confidence: float
   - category: str (document category folder name)
   - generated_at: str (ISO timestamp)

4. QUESTION_GENERATION_PROMPT template string:
   - Follow pattern from 28-RESEARCH.md
   - Include persona details placeholder
   - Specify conversational Swedish tone
   - Request 3-5 questions with types: factual, procedural, situational, clarification
   - Emphasize section_reference requirement

Update src/qa/__init__.py to export:
- GeneratedQuestion, QuestionBatch, QuestionEntry from question.py
  </action>
  <verify>
python -c "from src.qa import GeneratedQuestion, QuestionBatch, QuestionEntry; print('Models imported successfully')"
  </verify>
  <done>Pydantic models for question generation exist and are importable from src.qa</done>
</task>

<task type="auto">
  <name>Task 2: Implement generation logic with batch processing and deduplication</name>
  <files>src/qa/question.py</files>
  <action>
Add to src/qa/question.py:

1. generate_questions_for_document() function:
   - Takes document_path: Path, persona: Persona, delay: float = 0.1
   - Reads document text, extracts category from parent folder name
   - Calls Gemini API using existing pattern from src/ai/gemini.py:
     - client = genai.Client(api_key=api_key)
     - response_schema=QuestionBatch for structured output
     - model="gemini-3-flash-preview"
   - Transforms GeneratedQuestion list to QuestionEntry list with full metadata
   - Returns list[QuestionEntry] or empty list on failure
   - Log failures with logger.warning, don't raise exceptions

2. select_persona_for_document() function:
   - Takes document_path: Path, personas: list[Persona]
   - Simple heuristics from 28-RESEARCH.md:
     - "introduktion", "nyanstall", "grundlaggande", "checklista" -> nyanstald persona
     - "natt", "jour", "beredskap" -> persona with "natt" in situation
     - Default: random.choice(personas) for variety
   - Returns Persona

3. process_documents_batch() function:
   - Takes documents: list[Path], personas: list[Persona], max_workers: int = 5, delay: float = 0.2
   - Uses Rich progress bar (from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn)
   - ThreadPoolExecutor for parallel processing (from concurrent.futures)
   - Each document: select_persona_for_document() then generate_questions_for_document()
   - Returns list[QuestionEntry] (all questions flattened)

4. deduplicate_questions() function:
   - Takes questions: list[QuestionEntry], threshold: float = 0.85
   - Uses difflib.SequenceMatcher for similarity check
   - Compares question.lower() strings
   - Returns unique list[QuestionEntry]

5. write_questions_yaml() function:
   - Takes questions: list[QuestionEntry], output_path: Path
   - Groups questions by category using collections.defaultdict
   - Creates output dict with: generated_at, total_questions, categories
   - Uses yaml.dump() with allow_unicode=True, default_flow_style=False
  </action>
  <verify>
python -c "
from src.qa.question import generate_questions_for_document, select_persona_for_document, process_documents_batch, deduplicate_questions, write_questions_yaml
print('All generation functions imported successfully')
"
  </verify>
  <done>Question generation, batch processing, deduplication, and YAML output functions exist</done>
</task>

<task type="auto">
  <name>Task 3: Wire CLI and test with sample documents</name>
  <files>generate_qa.py</files>
  <action>
Update generate_qa.py main() function to:

1. Replace TODO placeholder with actual implementation:
   - Import from src.qa: process_documents_batch, deduplicate_questions, write_questions_yaml
   - Find all .md files in args.input (use rglob("*.md"))
   - If args.file is set: process only that single file
   - Otherwise: process all documents

2. Single file mode (--file):
   - Call generate_questions_for_document() directly
   - Print questions to console for inspection
   - Don't write YAML

3. Batch mode (default):
   - Call process_documents_batch() with Rich progress
   - Call deduplicate_questions()
   - Call write_questions_yaml() to args.output / "questions.yaml"
   - Print summary: total questions, unique after dedup, output path

4. Verbose mode (--verbose):
   - Set logging level to DEBUG
   - Print token usage if available

5. Add --limit argument:
   - Optional int to limit number of documents processed
   - Useful for testing without processing all 1143 docs

Test the complete flow:
   - Run: python generate_qa.py --file converted/Hemtjanst/[pick one].md --verbose
   - Verify questions generated and printed
   - Run: python generate_qa.py --limit 5
   - Verify qa/questions.yaml created with questions
  </action>
  <verify>
# Test single file mode (requires GEMINI_API_KEY)
python generate_qa.py --file "converted/Boendestod/Basala hygienrutiner boendestod.md" --verbose 2>&1 | head -30

# Verify output structure
ls -la qa/
  </verify>
  <done>CLI generates questions from documents, single-file mode works for testing, batch mode creates qa/questions.yaml</done>
</task>

</tasks>

<verification>
1. Models validate correctly:
   python -c "from src.qa import GeneratedQuestion, QuestionEntry; print('OK')"

2. Single file generates questions (requires GEMINI_API_KEY):
   python generate_qa.py --file converted/Hemtjanst/[any].md --verbose

3. Batch processing works with limit:
   python generate_qa.py --limit 3

4. Output file created with correct structure:
   python -c "import yaml; q=yaml.safe_load(open('qa/questions.yaml')); print(f\"Categories: {list(q['categories'].keys())}\")"

5. Requirements met:
   - QGEN-01: Generera fragor fran dokumentinnehall med Gemini (check: questions.yaml has questions)
   - QGEN-02: Persona-drivna fragor (check: persona field in each question)
   - QGEN-03: Kalldokumentreferens (check: source_document and section fields)
   - QGEN-04: 3-5 fragor per dokument (check: 3-5 questions per source_document)
   - QGEN-05: Batch-generering med progress (check: Rich progress bar shown)
</verification>

<success_criteria>
- src/qa/question.py exists with GeneratedQuestion, QuestionBatch, QuestionEntry models
- generate_qa.py --file [doc].md produces 3-5 questions printed to console
- generate_qa.py --limit N processes N documents with progress bar
- qa/questions.yaml contains questions grouped by category with full metadata
- Each question has: question text, source_document, section, question_type, persona dict, confidence, category, generated_at
</success_criteria>

<output>
After completion, create `.planning/phases/28-question-generation/28-01-SUMMARY.md`
</output>
