---
phase: 30-validation-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/qa/validator.py
  - src/qa/__init__.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Source verification computes semantic similarity for answer vs cited documents"
    - "LLM-as-judge scores relevans, korrekthet, fullstandighet on 0-1 scale"
    - "Composite score combines source + quality with configurable weights"
    - "ValidationResult includes pass/fail, scores, and reasoning"
  artifacts:
    - path: "src/qa/validator.py"
      provides: "Two-stage validation pipeline core"
      exports: ["SourceVerification", "QualityAssessment", "ValidationResult", "verify_source", "assess_quality", "validate_qa_pair"]
  key_links:
    - from: "src/qa/validator.py"
      to: "src/qa/retriever.py"
      via: "SwedishRetriever for semantic similarity"
      pattern: "retriever\\.retrieve"
    - from: "src/qa/validator.py"
      to: "google.genai"
      via: "LLM-as-judge calls"
      pattern: "client\\.models\\.generate_content"
---

<objective>
Create the validation module core with two-stage pipeline: source verification (semantic similarity + LLM for borderline) and quality assessment (LLM-as-judge scoring three dimensions).

Purpose: Provides the validation logic to filter hallucinations and low-quality QA pairs before export for AI training.
Output: src/qa/validator.py with Pydantic models and validation functions.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/30-validation-pipeline/30-RESEARCH.md
@.planning/phases/30-validation-pipeline/30-CONTEXT.md
@.planning/phases/29-answer-generation/29-02-SUMMARY.md

# Existing code to follow patterns from
@src/qa/answer.py
@src/qa/retriever.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Pydantic models for validation results</name>
  <files>src/qa/validator.py</files>
  <action>
Create src/qa/validator.py with Pydantic models following the patterns from answer.py:

```python
class SourceVerification(BaseModel):
    """Stage 1: Source verification result."""
    is_grounded: bool = Field(description="Whether answer content exists in cited sources")
    similarity_score: float = Field(ge=0.0, le=1.0, description="Semantic similarity score")
    reasoning: str = Field(description="Explanation of verification result")
    ungrounded_claims: list[str] = Field(default_factory=list, description="Claims not found in sources")

class QualityAssessment(BaseModel):
    """Stage 2: LLM-as-judge quality scores."""
    relevans: float = Field(ge=0.0, le=1.0, description="How well answer addresses the question")
    korrekthet: float = Field(ge=0.0, le=1.0, description="Factual accuracy of the answer")
    fullstandighet: float = Field(ge=0.0, le=1.0, description="Completeness of the answer")
    reasoning: str = Field(description="Explanation of quality assessment")

class ValidationResult(BaseModel):
    """Combined validation result for a QA pair."""
    passed: bool
    composite_score: float = Field(ge=0.0, le=1.0)
    source_verification: SourceVerification
    quality_assessment: QualityAssessment | None  # None if source verification failed
    failure_reason: str | None = None
```

Include standard imports (logging, os, Pydantic, typing). Add module docstring describing two-stage validation.
  </action>
  <verify>python -c "from src.qa.validator import SourceVerification, QualityAssessment, ValidationResult; print('Models import OK')"</verify>
  <done>Three Pydantic models exist with proper Field constraints and descriptions</done>
</task>

<task type="auto">
  <name>Task 2: Implement source verification with semantic similarity</name>
  <files>src/qa/validator.py</files>
  <action>
Add verify_source() function that:

1. Extracts claims from answer text (split by sentence, filter trivial sentences)
2. Uses SwedishRetriever to compute similarity for each claim against cited documents
3. Applies thresholds from RESEARCH.md:
   - score >= 0.75: auto-pass
   - score 0.5-0.75: use LLM judge for borderline verification
   - score < 0.5: auto-fail

Function signature:
```python
def verify_source(
    answer_text: str,
    citations: list[dict],  # [{document: str, section: str}]
    retriever: SwedishRetriever,
    similarity_threshold: float = 0.75,
    borderline_threshold: float = 0.5
) -> SourceVerification:
```

For borderline cases (0.5-0.75), add LLM verification using Gemini with prompt asking:
- "Does the answer claim '{claim}' exist in this source text: {chunk_content}?"
- Return structured response with is_supported: bool and reasoning

Use existing Gemini pattern from answer.py (genai.Client, generate_content with response_schema).
  </action>
  <verify>python -c "from src.qa.validator import verify_source; print('verify_source imports OK')"</verify>
  <done>verify_source() returns SourceVerification with similarity score and reasoning</done>
</task>

<task type="auto">
  <name>Task 3: Implement quality assessment and composite scoring</name>
  <files>src/qa/validator.py, src/qa/__init__.py</files>
  <action>
Add assess_quality() function using LLM-as-judge:

1. Create QUALITY_ASSESSMENT_PROMPT (Swedish) from RESEARCH.md pattern:
   - Explains 0-1 scale for each dimension with examples
   - Requires reasoning before scores
   - Dimension definitions: relevans, korrekthet, fullstandighet

2. Function signature:
```python
def assess_quality(
    question: str,
    answer: str,
    sources: str,  # Formatted source content for context
) -> QualityAssessment | None:
```

Uses Gemini structured output with QualityAssessment schema.

Add compute_composite_score() function:
```python
def compute_composite_score(
    source_score: float,
    quality: QualityAssessment,
    weights: dict[str, float] | None = None
) -> float:
```

Default weights from RESEARCH.md:
- source: 0.3
- relevans: 0.2
- korrekthet: 0.3 (highest - accuracy critical for training)
- fullstandighet: 0.2

Add validate_qa_pair() that orchestrates the two stages:
```python
def validate_qa_pair(
    qa_entry: dict,
    retriever: SwedishRetriever,
    doc_contents: dict[str, str],  # For LLM judge context
    threshold: float = 0.7
) -> ValidationResult:
```

Logic:
1. Run verify_source() - if similarity_score < borderline_threshold and LLM says not grounded, return early with passed=False
2. Run assess_quality() with retrieved source content
3. Compute composite score
4. Return ValidationResult with passed = composite_score >= threshold

Update src/qa/__init__.py to export:
- SourceVerification, QualityAssessment, ValidationResult
- verify_source, assess_quality, validate_qa_pair, compute_composite_score
  </action>
  <verify>
python -c "from src.qa import validate_qa_pair, compute_composite_score; print('Validator exports OK')"
  </verify>
  <done>
- assess_quality() calls Gemini with structured output for three dimensions
- compute_composite_score() uses weighted combination
- validate_qa_pair() orchestrates two stages and returns ValidationResult
- All exports added to __init__.py
  </done>
</task>

</tasks>

<verification>
Run all validation checks:
```bash
# Models import correctly
python -c "from src.qa.validator import SourceVerification, QualityAssessment, ValidationResult"

# Functions import correctly
python -c "from src.qa import verify_source, assess_quality, validate_qa_pair, compute_composite_score"

# Module has correct structure
python -c "import src.qa.validator as v; print([x for x in dir(v) if not x.startswith('_')])"
```
</verification>

<success_criteria>
- src/qa/validator.py exists with ~150-200 lines
- Three Pydantic models with proper validation constraints
- verify_source() computes semantic similarity and handles borderline cases
- assess_quality() uses LLM-as-judge with Swedish prompt
- validate_qa_pair() returns complete ValidationResult with composite score
- All components exported from src/qa/__init__.py
</success_criteria>

<output>
After completion, create `.planning/phases/30-validation-pipeline/30-01-SUMMARY.md`
</output>
