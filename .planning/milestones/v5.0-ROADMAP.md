# Milestone v5.0: QA Generation Pipeline

**Status:** ✅ SHIPPED 2026-02-19
**Phases:** 27-31
**Total Plans:** 8

## Overview

This milestone built a complete QA generation pipeline that transforms the existing knowledge base (1,086 converted markdown documents) into thousands of validated question-answer pairs for AI assistant training. The pipeline progresses through persona modeling, question generation, answer grounding, validation, and export - each phase delivering a complete, testable capability that feeds the next.

## Phases

### Phase 27: Core Infrastructure

**Goal**: Establish persona model and QA module structure as foundation for generation pipeline
**Depends on**: v4.0 complete (converted documents exist in KB)
**Plans**: 1 plan

Plans:
- [x] 27-01: Create persona model, YAML config, and CLI scaffold

**Details:**
- Persona Pydantic model with computed ID format: {roll}-{erfarenhet}-{sprakbakgrund}
- 5 realistic undersköterska personas in YAML config with varied experience/language combinations
- generate_qa.py CLI scaffold with --input, --output, --personas arguments
- src/qa module structure with clean exports
- Literal types for constrained field validation

### Phase 28: Question Generation

**Goal**: Generate 3-5 diverse questions per document using persona-driven prompts
**Depends on**: Phase 27 (persona model required)
**Plans**: 1 plan

Plans:
- [x] 28-01: Question generation with Pydantic models, Gemini integration, batch processing

**Details:**
- GeneratedQuestion, QuestionBatch, QuestionEntry Pydantic models for structured LLM output
- select_persona_for_document() with heuristics (intro docs → nyanställd, night shift → natt persona)
- Gemini API integration with rate limiting (max_workers=5, delay=0.2s)
- Batch processing with ThreadPoolExecutor and Rich progress bars
- Deduplication with difflib.SequenceMatcher (0.85 similarity threshold)
- Model: gemini-2.0-flash

### Phase 29: Answer Generation

**Goal**: Generate grounded answers with explicit source citations in plain Swedish
**Depends on**: Phase 28 (questions required)
**Plans**: 2 plans

Plans:
- [x] 29-01: Semantic retrieval infrastructure (chunking, Swedish embeddings, FAISS index)
- [x] 29-02: Answer generation with citations and CLI integration

**Details:**
- KBLab/sentence-bert-swedish-cased embeddings (0.918 Pearson on SweParaphrase)
- 512-token chunks with 128-token overlap per Microsoft RAG guidelines
- FAISS IndexFlatIP with L2 normalization for cosine similarity
- Extraction-style prompting: prefer direct quotes over paraphrasing
- Citation format [source:document.md#section] inline immediately after content
- Klarspråk enforcement: max 15 words per sentence, active voice, du-tilltal
- Coverage tracking: full/partial/none with confidence score 0.0-1.0

### Phase 30: Validation Pipeline

**Goal**: Two-stage validation filtering out hallucinations and low-quality pairs
**Depends on**: Phase 29 (QA pairs required)
**Plans**: 2 plans

Plans:
- [x] 30-01: Validation module core (Pydantic models, source verification, quality assessment)
- [x] 30-02: CLI integration and batch processing with JSONL output

**Details:**
- Semantic similarity thresholds: ≥0.75 auto-pass, 0.5-0.75 LLM borderline check, <0.5 auto-fail
- Three-dimension quality scoring: relevans, korrekthet, fullständighet
- Composite weights: source 0.3, korrekthet 0.3, relevans 0.2, fullständighet 0.2
- Early exit if source verification fails to save API calls
- JSONL output with complete validation objects
- Pass/reject threshold at 0.7 composite score

### Phase 31: Export & Integration

**Goal**: Complete pipeline with JSONL export and integration into main workflow
**Depends on**: Phase 30 (validated QA pairs required)
**Plans**: 2 plans

Plans:
- [x] 31-01: HuggingFace export module and CLI --export mode
- [x] 31-02: Checkpointing and pipeline.py --generate-qa integration

**Details:**
- Flat HuggingFace structure: question, answer, source, persona, validation_score
- Persona format: {roll}/{erfarenhet} string for simplicity
- ensure_ascii=False for Swedish character preservation
- Stage-level checkpointing with input hash for change detection
- Atomic file writes via tempfile + rename for crash safety
- Pipeline QA stages warn on failure but don't abort entire pipeline

---

## Milestone Summary

**Key Decisions:**
- Persona ID format: {roll}-{erfarenhet}-{sprakbakgrund}
- Model: gemini-2.0-flash (gemini-3-flash-preview not available)
- Embedding model: KBLab/sentence-bert-swedish-cased
- Chunk size: 512 tokens with 128 overlap
- Vector search: FAISS IndexFlatIP with L2 normalization
- Extraction-style prompting over paraphrasing
- Similarity thresholds: ≥0.75 auto-pass, 0.5-0.75 LLM check, <0.5 auto-fail
- Composite score weights: source 0.3, korrekthet 0.3, relevans 0.2, fullständighet 0.2
- Pass/reject threshold: 0.7
- Stage-level checkpointing (not per-file)

**Issues Resolved:**
- gemini-3-flash-preview API unavailable → switched to gemini-2.0-flash
- Plan 29-02 revised to prioritize extraction-style generation over paraphrasing

**Issues Deferred:**
- None

**Technical Debt Incurred:**
- None

---

_For current project status, see .planning/PROJECT.md_
